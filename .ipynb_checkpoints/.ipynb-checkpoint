{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the Average Height of US Presidents?\n",
    "\n",
    "Aggregates available in NumPy can be extremely useful for summarizing a set of values.\n",
    "As a simple example, let's consider the heights of all US presidents.\n",
    "\n",
    "This data is available in the file *president_heights.csv*, which is a simple comma-separated list of labels and values.\n",
    "\n",
    "Find the mean height, the standard deviation of height, and the president who is the smallest and tallest.\n",
    "\n",
    "You can use `pandas` to read in the file if you want, then cast the column to a `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"president_heights.csv\")\n",
    "\n",
    "# The average height of US Presidents is about 179.74 cm.\n",
    "np.mean(df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The standard deviation of height is about 6.93.\n",
    "np.std(df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smallest US Presidents is about 163 cm.\n",
    "np.amin(df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Tallest US Presidents is about 193 cm.\n",
    "np.amax(df, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Recall the polynomial formula\n",
    "\n",
    "$$\n",
    "p(x) = a_0 + a_1 x + a_2 x^2 + \\cdots a_N x^N = \\sum_{n=0}^N a_n x^n \\tag{1}\n",
    "$$\n",
    "\n",
    "In the **math functions workshop**, you wrote a simple function `p(x, coeff)` to evaluate it without thinking about efficiency.\n",
    "\n",
    "Now write a new function that does the same job, but uses NumPy arrays and array operations for its computations, rather than any form of Python loop.\n",
    "\n",
    "(This is already implemented in `np.poly1d`, but use that only to test your function)\n",
    "\n",
    "- Hint: Use `np.cumprod()`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def p(x, coeff):\n",
    "    coeff = np.array(coeff)\n",
    "    N = np.arange(len(coeff))\n",
    "    math_operation = (coeff * x ** N)\n",
    "    return np.sum(math_operation)\n",
    "\n",
    "    \n",
    "p(6,[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Softmax\n",
    "\n",
    "Read in `data/iris.csv` and compute the [softmax]() of the sepal length. The formula for the softmax function $\\sigma(x)$ for a vector $x = \\{x_0, x_1, ..., x_{n-1}\\}$ is\n",
    "    .$$\\sigma(x)_j = \\frac{e^{x_j}}{\\sum_k e^{x_k}}$$\n",
    "\n",
    "\n",
    "Your result should be equal to the output of `scipy.special.softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "value = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "sepal_length = np.array(value[\"sepallength\"])\n",
    "\n",
    "σ = (np.exp(sepal_length) / (np.sum(np.exp(sepal_length))))\n",
    "\n",
    "σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: unique counts\n",
    "\n",
    "\n",
    "Compute the counts of unique values row-wise.\n",
    "\n",
    "Input:\n",
    "```\n",
    "np.random.seed(100)\n",
    "arr = np.random.randint(1,11,size=(6, 10))\n",
    "arr\n",
    "> array([[ 9,  9,  4,  8,  8,  1,  5,  3,  6,  3],\n",
    ">        [ 3,  3,  2,  1,  9,  5,  1, 10,  7,  3],\n",
    ">        [ 5,  2,  6,  4,  5,  5,  4,  8,  2,  2],\n",
    ">        [ 8,  8,  1,  3, 10, 10,  4,  3,  6,  9],\n",
    ">        [ 2,  1,  8,  7,  3,  1,  9,  3,  6,  2],\n",
    ">        [ 9,  2,  6,  5,  3,  9,  4,  6,  1, 10]])\n",
    "```\n",
    "Desired Output:\n",
    "```\n",
    "> [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],\n",
    ">  [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],\n",
    ">  [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],\n",
    ">  [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],\n",
    ">  [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],\n",
    ">  [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]]\n",
    "```\n",
    "Output contains 10 columns representing numbers from 1 to 10. The values are the counts of the numbers in the respective rows.\n",
    "For example, Cell(0,2) has the value 2, which means, the number 3 occurs exactly 2 times in the 1st row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "arr = np.random.randint(1, 11, size = (6, 10))\n",
    "\n",
    "arr_copy = np.array(arr, copy = True)\n",
    "\n",
    "n_row = len(arr_copy)\n",
    "n_col = len(arr_copy[0])\n",
    "\n",
    "n = np.arange(1, 11)\n",
    "\n",
    "for j in range(n_row):\n",
    "    for i in range(n_col):\n",
    "        arr[j, i] = len(np.where(arr_copy[rows,] == n[cols])[0])\n",
    "        \n",
    "        \n",
    "print(arr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: One-Hot encodings\n",
    "\n",
    "Compute the one-hot encodings (AKA dummy binary variables) for each unique value in the array.\n",
    "\n",
    "Input:\n",
    "```\n",
    "np.random.seed(101) \n",
    "arr = np.random.randint(1,4, size=6)\n",
    "arr\n",
    "#> array([2, 3, 2, 2, 2, 1])\n",
    "```\n",
    "Output:\n",
    "```\n",
    "#> array([[ 0.,  1.,  0.],\n",
    "#>        [ 0.,  0.,  1.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 1.,  0.,  0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(101) \n",
    "arr = np.random.randint(1,4, size = 6)\n",
    "arr_2 = pd.get_dummies(arr)\n",
    "\n",
    "array = arr_2.values.tolist()\n",
    "\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Let `q` be a NumPy array of length `n` with `q.sum() == 1`.\n",
    "\n",
    "Suppose that `q` represents a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function) over a statistical distribution. Recall that a distribution is an array of probabilities of events.\n",
    "\n",
    "We want to generate a discrete random variable $ x $ such that $ \\mathbb P\\{x = i\\} = q_i $.\n",
    "\n",
    "In other words, `x` takes values in `range(len(q))` and `x = i` with probability `q[i]`.\n",
    "\n",
    "The standard (inverse transform) algorithm is as follows:\n",
    "\n",
    "- Divide the unit interval $ [0, 1] $ into $ n $ subintervals $ I_0, I_1, \\ldots, I_{n-1} $ such that the length of $ I_i $ is $ q_i $.  \n",
    "- Draw a uniform random variable $ U $ on $ [0, 1] $ and return the $ i $ such that $ U \\in I_i $.  \n",
    "\n",
    "\n",
    "The probability of drawing $ i $ is the length of $ I_i $, which is equal to $ q_i $.\n",
    "\n",
    "We can implement the algorithm as follows\n",
    "\n",
    "```python\n",
    "from random import uniform\n",
    "\n",
    "def sample(q):\n",
    "    a = 0.0\n",
    "    U = uniform(0, 1)\n",
    "    for i in range(len(q)):\n",
    "        if a < U <= a + q[i]:\n",
    "            return i\n",
    "        a = a + q[i]\n",
    "```\n",
    "\n",
    "If you can’t see how this works, try thinking through the flow for a simple example, such as `q = [0.25, 0.75]`\n",
    "It helps to sketch the intervals on paper.\n",
    "\n",
    "**Your exercise is to speed it up using NumPy, avoiding explicit loops**\n",
    "\n",
    "- Hint: Use `np.searchsorted` and `np.cumsum`  \n",
    "\n",
    "\n",
    "If you can, implement the functionality as a class called `DiscreteRV`, where\n",
    "\n",
    "- the data for an instance of the class is the vector of probabilities `q`  \n",
    "- the class has a `draw()` method, which returns one draw according to the algorithm described above  \n",
    "\n",
    "\n",
    "If you can, write the method so that `draw(k)` returns `k` draws from `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "def sample(q):\n",
    "    a = 0.0\n",
    "    U = uniform(0, 1)\n",
    "    for i in range(len(q)):\n",
    "        if a < U <= a + q[i]:\n",
    "            return i\n",
    "        a = a + q[i]\n",
    "\n",
    "sample([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample2(q):\n",
    "    a = 0.0\n",
    "    U = uniform(0, 1)\n",
    "    np.cumsum(q)\n",
    "    return np.searchsorted(q, U)\n",
    "    \n",
    "A = [0.25, 0.75]\n",
    "sample2(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 Peaks\n",
    "\n",
    "Find all the peaks in a 1D numpy array a. Peaks are points surrounded by smaller values on both sides.\n",
    "\n",
    "Input:\n",
    "```\n",
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "```\n",
    "Desired Output:\n",
    "```\n",
    "#> array([2, 5])\n",
    "```\n",
    "where, 2 and 5 are the positions of peak values 7 and 6.\n",
    "\n",
    "### 1. Solve this usign a regular python for loop\n",
    "\n",
    "### 2. Solve this using no loops and only numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a regular python for loop\n",
    "\n",
    "array = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "\n",
    "peaks_in_a_1D_numpy_array = []\n",
    "\n",
    "for n in range (1,len(array)-1):\n",
    "    if (array[n] > array[n + 1]) & (array[n] > array[n - 1]):\n",
    "        peaks_in_a_1D_numpy_array.append(n)\n",
    "\n",
    "print(peaks_in_a_1D_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using no loops and only numpy functions\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "array = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "\n",
    "print(find_peaks(array))"
   ]
  }
 ],
 "metadata": {
  "date": 1597540028.6350708,
  "filename": "numpy.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "next_doc": {
   "link": "matplotlib",
   "title": "Matplotlib"
  },
  "prev_doc": {
   "link": "need_for_speed",
   "title": "Python for Scientific Computing"
  },
  "title": "NumPy"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
